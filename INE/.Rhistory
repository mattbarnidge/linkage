maxiter=3000, tol=1e-5,
na.rm=FALSE, nrep=10,
verbose=TRUE, calc.se=TRUE)
if(lc$bic < min_bic){
min_bic <- lc$bic
LCA_best_model <- lc
}
}
#Print results (3-class model is best, according to BIC)
print(LCA_best_model)
#Estimate Model, re-set order based on predicted probabilities
#(biggest group first), then re-estimate models
lc <- poLCA(f, x, nclass=3,
maxiter=3000, tol=1e-5,
na.rm=TRUE,  nrep=10,
verbose=TRUE, calc.se=TRUE,
graph=TRUE) #initial model
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
mean(x$pol); sd(x$pol)
mean(x$ipe); sd(x$ipe)
summary(x$pol)
summary(x$ipe)
names(x)
table(x$recall)
842/2008
table(x$incexp)
table(x$incexp, x$recall)
388+454
454/2008
454/842
names(x)
table(x$story.engage)
with(subset(x$recall==1), mean(story.engage))
with(subset(x, recall==1), mean(story.engage))
with(subset(x, recall==1), sd(story.engage))
with(subset(x, recall==1), mean(story.engage.he))
with(subset(x, recall==1), sd(story.engage.he))
table(x$story.engage.he)
table(x$mot)
709/2008
table(x$int)
mean(x$int); sd(x$int)
mean(x$fol); sd(x$fol); summary(x$fol)
table(x$alg)
833/2008
names(x)
summary(x$size); mean(x$size); sd(x$size)
summary(x$div); mean(x$div); sd(x$div)
hist(x$div)
summary(x$grp); mean(x$grp); sd(x$grp)
summary(x$cur); mean(x$cur); sd(x$cur)
names(x)
summary(x$age); mean(x$age); sd(x$age)
table(x$female)
table(x$poc)
summary(x$edu); mean(x$edu); sd(x$edu)
summary(x$inc); mean(x$inc); sd(x$inc)
summary(x$ideo); mean(x$ideo); sd(x$ideo)
summary(x$pid); mean(x$pid); sd(x$pid)
summary(x$sm.freq); mean(x$sm.freq); sd(x$sm.freq)
1027/2008
809/2008
#Load Libraries
library(dplyr)
library(tidyr)
#Set WD and load data
setwd("~/Documents/GitHub/linkage/INE")
load("ine.Rdata")
#Correlations among indicators of involvement (.33 < r < .53)
with(x, round(cor(cbind(mot, int, fol, alg),
use="complete.obs"), digits=2))
#LCA based on indicators of involvement
#Recode variables for LCA (LCA requires non-zero integers)
x$x1 = x$mot + 1
x$x2 = round(x$int, digits = 0)
x$x3 = round(x$fol, digits = 0)
x$x4 = x$alg + 1
#Define LCA function
f <- cbind(x1, x2, x3, x4) ~ 1
#Load Library for LCA
library(poLCA)
#Write function to find best fitting model
#min = 2 classes, max = 5 classes (trouble with convergence above 5)
min_bic <- 100000
for(i in 2:5){
lc <- poLCA(f, x, nclass=i,
maxiter=3000, tol=1e-5,
na.rm=FALSE, nrep=10,
verbose=TRUE, calc.se=TRUE)
if(lc$bic < min_bic){
min_bic <- lc$bic
LCA_best_model <- lc
}
}
#Print results (3-class model is best, according to BIC)
print(LCA_best_model)
#Estimate Model, re-set order based on predicted probabilities
#(biggest group first), then re-estimate models
lc <- poLCA(f, x, nclass=3,
maxiter=3000, tol=1e-5,
na.rm=TRUE,  nrep=10,
verbose=TRUE, calc.se=TRUE,
graph=TRUE) #initial model
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
#Clean up environment
rm(f,
i,
min_bic,
LCA_best_model,
probs.start)
detach("package:poLCA", unload=TRUE)
#Extract grouping variable and add to dataset
x$inv = as.factor(lc$predclass)
table(x$inv)
#Group 1 = low involvement (48%)
#Group 2 = medium involvement (37.5%)
#Group 3 = high involvement (14.5%)
library(lme4)
library(lmerTest)
lm1 = lmer(ipe ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur +
(1 | frame),
data=x, weights=weights,
control=lmerControl(optimizer="bobyqa"))
lg1 = glmer(incexp.sk ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=x, family=poisson, weights=weights,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
lm2 = lmer(pol ~ inv + iny +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur +
(1 | frame),
data=x, weights=weights,
control=lmerControl(optimizer="bobyqa"))
lg2 = glmer(recall ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=x, family=poisson, weights=weights,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(lm1, cor=FALSE)
summary(lg1, cor=FALSE)
x$incexp = as.factor(x$incexp)
lg3 = lmer(story.engage ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
lg4 = lmer(story.engage.he ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(lg3, cor=FALSE)
summary(lg4, cor=FALSE)
#Load Libraries
library(dplyr)
library(tidyr)
#Set WD and load data
setwd("~/Documents/GitHub/linkage/INE")
load("ine.Rdata")
#Correlations among indicators of involvement (.33 < r < .53)
with(x, round(cor(cbind(mot, int, fol, alg),
use="complete.obs"), digits=2))
#Recode variables for LCA (LCA requires non-zero integers)
x$x1 = x$mot + 1
x$x2 = round(x$int, digits = 0)
x$x3 = round(x$fol, digits = 0)
x$x4 = x$alg + 1
#Define LCA function
f <- cbind(x1, x2, x3, x4) ~ 1
library(poLCA)
min_bic <- 100000
for(i in 2:5){
lc <- poLCA(f, x, nclass=i,
maxiter=3000, tol=1e-5,
na.rm=FALSE, nrep=10,
verbose=TRUE, calc.se=TRUE)
if(lc$bic < min_bic){
min_bic <- lc$bic
LCA_best_model <- lc
}
}
print(LCA_best_model)
lc <- poLCA(f, x, nclass=3,
maxiter=3000, tol=1e-5,
na.rm=TRUE,  nrep=10,
verbose=TRUE, calc.se=TRUE,
graph=TRUE) #initial model
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
#Clean up environment
rm(f,
i,
min_bic,
LCA_best_model,
probs.start)
detach("package:poLCA", unload=TRUE)
x$inv = as.factor(lc$predclass)
table(x$inv)
library(lme4)
library(lmerTest)
x$incexp = as.factor(x$incexp)
x$inv <- factor(x$inv,
levels = c(1,2,3),
labels = c("Low", "Med", "High"))
x$incexp <- factor(x$incexp,
levels = c(0,1),
labels = c("Purp.", "Inc."))
lg4.v = lmer(story.engage.he ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
par(mfrow=c(1,1))
visreg::visreg(lg4.v, "incexp", by="inv", jitter=TRUE, line=list(col="black"),
ylab="High-Effort Engagement", xlab="Exposure Type")
#Load Libraries
library(dplyr)
library(tidyr)
#Set WD and Load Data
setwd("~/Documents/GitHub/linkage/INE")
load("EMCP20_coded.Rdata")
#Exposure and Incidentality:
d$pol = d$sminc - 1 #social media political information; making "never" = 0
d$iny = d$smincexp2 - 1 #incidentality; making "never" = 0
d$ipe = sqrt(d$pol*d$iny)
d$recall = d$story.aware #recall of embedded story (state)
d$incexp = abs(d$story.purp - 1) #incidentally exposed to story (no skips)
#Engagement
table(d$engage)
table(d$story.engage)
#Control Variables
summary(d$age)
summary(d$female)
summary(d$poc)
summary(d$edu)
summary(d$inc)
summary(d$ideo)
summary(d$pid)
summary(d$sm.freq)
#Interests and Involvement
d$mot = d$sm.newsintent #social media as news source
summary(d$int) #interest
d$fol = d$smfollow #following accounts for news
d$alg[d$alg==2] <- 1 #algorithmic categorization
#Social Networks
d$size = log(d$sm.ns) #network size, logged
d$div = d$sm.div.occ #network diversity, sociostructural
d$grp = log(d$grp) #social media groups, logged
d$cur = d$smcur #social curation
#Rolling Covariates
table(d$story.mult) #multiple exposures
d$cong <- NA
d$cong = ifelse(d$story.part == 1 & d$ideo > 0, 1, d$cong)
d$cong = ifelse(d$story.part == 0 & d$ideo < 0, 1, d$cong)
d$cong = ifelse(d$ideo == 0, 0, d$cong)
d$cong = ifelse(d$story.part == 1 & d$ideo < 0, -1, d$cong)
d$cong = ifelse(d$story.part == 0 & d$ideo > 0, -1, d$cong) #ideological congruence
d$storypart = abs(d$storypart - 6) #perceived partisanship (extremity)
table(d$storycandeval) #relevance for evaluating candidates
with(d, ltm::cronbach.alpha(cbind(storyemo.joy,
storyemo.enth,
storyemo.ang,
storyemo.fear), na.rm=TRUE))
d$storyemo = with(d, rowMeans(cbind(storyemo.joy,
storyemo.enth,
storyemo.ang,
storyemo.fear), na.rm=TRUE)) #emotional response
table(d$curatoreval) #evaluation of curator
names(d)
summary(d$nsmnews)
hist(d$nsmnews)
#Select Variables
x <- d %>% select(pol, iny, ipe, engage, nsmnews,
age, female, poc, edu, inc, ideo, pid, sm.freq,
mot, int, fol, alg,
size, div, grp, cur,
recall, incexp, story.engage, story.engage.he,
story.mult, cong, storypart,
storycandeval, storyemo, curatoreval,
frame, weights)
#Multiple Imputation
t1 <- mice::mice(x[,1:21], m=1, maxit=50, meth='pmm', seed=500)
t2 <- mice::mice(x[,22:31], m=1, maxit=50, meth='pmm', seed=500)
x[,1:21] <- mice::complete(t1, 1)
x[,22:31] <- mice::complete(t2, 1)
rm(t1, t2)
x <- na.omit(x)
#Create some additional variables (didn't want these in multiple imputation)
x$incexp.sk = ifelse(x$recall == 1 & x$incexp == 1, 1, 0) #include skips
x$incexp.f1 = ifelse(x$recall == 1 & x$incexp == 1, "inc",
ifelse(x$recall == 1 & x$incexp == 0, "purp",
"none"))
x$incexp.f1 = factor(x$incexp.f1, levels=c("none", "inc", "purp"))
x$incexp.f2 = factor(x$incexp.f1, levels=c("inc", "none", "purp"))
save(x, file="ine.Rdata")
rm(d, x)
#Load Libraries
library(dplyr)
library(tidyr)
#Set WD and load data
setwd("~/Documents/GitHub/linkage/INE")
load("ine.Rdata")
#Correlations among indicators of involvement (.33 < r < .53)
with(x, round(cor(cbind(mot, int, fol, alg),
use="complete.obs"), digits=2))
#Recode variables for LCA (LCA requires non-zero integers)
x$x1 = x$mot + 1
x$x2 = round(x$int, digits = 0)
x$x3 = round(x$fol, digits = 0)
x$x4 = x$alg + 1
f <- cbind(x1, x2, x3, x4) ~ 1
library(poLCA)
min_bic <- 100000
for(i in 2:5){
lc <- poLCA(f, x, nclass=i,
maxiter=3000, tol=1e-5,
na.rm=FALSE, nrep=10,
verbose=TRUE, calc.se=TRUE)
if(lc$bic < min_bic){
min_bic <- lc$bic
LCA_best_model <- lc
}
}
print(LCA_best_model)
lc <- poLCA(f, x, nclass=3,
maxiter=3000, tol=1e-5,
na.rm=TRUE,  nrep=10,
verbose=TRUE, calc.se=TRUE,
graph=TRUE) #initial model
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
#Clean up environment
rm(f,
i,
min_bic,
LCA_best_model,
probs.start)
detach("package:poLCA", unload=TRUE)
x$inv = as.factor(lc$predclass)
table(x$inv)
#Load Libraries
library(lme4)
library(lmerTest)
am = lmer(nsmnews ~ inv +
age + female + poc + edu + inc + ideo + pid +
(1 | frame),
data=x, weights=weights,
control=lmerControl(optimizer="bobyqa"))
sqrt(car::vif(am)) > 2
summary(am, cor=FALSE); logLik(am); performance::r2(am); performance::icc(am)
visreg::visreg(am, "inv", jitter=TRUE, line=list(col="black"),
ylab="Non-Social Media News Use", xlab="News Attraction")
lm1 = lmer(ipe ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur +
(1 | frame),
data=x, weights=weights,
control=lmerControl(optimizer="bobyqa"))
lg1 = glmer(incexp.sk ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=x, family=poisson, weights=weights,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
lm2 = lmer(pol ~ inv + iny +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur +
(1 | frame),
data=x, weights=weights,
control=lmerControl(optimizer="bobyqa"))
lg2 = glmer(recall ~ inv +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=x, family=poisson, weights=weights,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
par(mfrow=c(2,2))
visreg::visreg(lm1, "inv", jitter=TRUE, line=list(col="black"),
main="Trait-Like DV", ylab="Incidental Exposure", xlab="")
visreg::visreg(lg1, "inv", jitter=TRUE, line=list(col="black"),
main="State-Like DV", ylab="Incisdental Exposure", xlab="")
visreg::visreg(lm2, "inv", jitter=TRUE, line=list(col="black"),
ylab="Total Exposure", xlab="Involvement")
visreg::visreg(lg2, "inv", jitter=TRUE, line=list(col="black"),
ylab="Story Exposure", xlab="Involvement")
lg3 = lmer(story.engage ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
lg4 = lmer(story.engage.he ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
#Add labels for visualization and refit models
x$inv <- factor(x$inv,
levels = c(1,2,3),
labels = c("Low", "Med", "High"))
x$incexp <- factor(x$incexp,
levels = c(0,1),
labels = c("Purp.", "Inc."))
lg3.v = lmer(story.engage ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
lg4.v = lmer(story.engage.he ~ inv*incexp +
age + female + poc + edu + inc + ideo + pid +
sm.freq + size + div + grp + cur + ipe +
(1 | frame),
data=subset(x, recall==1),
control=lmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
par(mfrow=c(1,1))
visreg::visreg(lg3.v, "incexp", by="inv", jitter=TRUE, line=list(col="black"),
ylab="Engagement", xlab="Exposure Type")
visreg::visreg(lg4.v, "incexp", by="inv", jitter=TRUE, line=list(col="black"),
ylab="High-Effort Engagement", xlab="Exposure Type")
summary(am, cor=FALSE); logLik(am); performance::r2(am); performance::icc(am)
options(scipen=999)
summary(am, cor=FALSE); logLik(am); performance::r2(am); performance::icc(am)
summary(lm1, cor=FALSE); logLik(lm1); performance::r2(lm1); performance::icc(lm1)
summary(lg1, cor=FALSE); logLik(lg1); performance::r2(lg1); performance::icc(lg1)
summary(lm2, cor=FALSE); logLik(lm2); performance::r2(lm2); performance::icc(lm2)
summary(lg2, cor=FALSE); logLik(lg2); performance::r2(lg1); performance::icc(lg2)
summary(lg3, cor=FALSE); logLik(lg3); performance::r2(lg3); performance::icc(lg3)
summary(lg4, cor=FALSE); logLik(lg4); performance::r2(lg4); performance::icc(lg4)
with(x, round(cor(cbind(mot, int, fol, alg),
use="complete.obs"), digits=2))
#Define LCA function
f <- cbind(x1, x2, x3, x4) ~ 1
#Load Library for LCA
library(poLCA)
#Write function to find best fitting model
#min = 2 classes, max = 5 classes (trouble with convergence above 5)
min_bic <- 100000
for(i in 2:5){
lc <- poLCA(f, x, nclass=i,
maxiter=3000, tol=1e-5,
na.rm=FALSE, nrep=10,
verbose=TRUE, calc.se=TRUE)
if(lc$bic < min_bic){
min_bic <- lc$bic
LCA_best_model <- lc
}
}
lc <- poLCA(f, x, nclass=3,
maxiter=3000, tol=1e-5,
na.rm=TRUE,  nrep=10,
verbose=TRUE, calc.se=TRUE,
graph=TRUE) #initial model
probs.start <- poLCA.reorder(lc$probs.start,
order(lc$P, decreasing=TRUE)) #create object for order
lc <- poLCA(f, x, nclass = 3,
maxiter=3000, tol=1e-5,
na.rm=TRUE, nrep=10,
verbose=TRUE, calc.se=TRUE,
probs.start = probs.start,
graph=TRUE) #refit model with order object (probs.start)
